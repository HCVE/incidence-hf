{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: sklearn.tree._splitter.Splitter size changed, may indicate binary incompatibility. Expected 360 from C header, got 1160 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# noinspection PyUnresolvedReferences\n",
    "from hcve_lib.tracking import load_run_results\n",
    "from hcve_lib.utils import notebook_init, run_parallel\n",
    "from hcve_lib.metrics import precision_recall_curve_with_confusion\n",
    "from hcve_lib.evaluation_functions import map_inverse_weight\n",
    "\n",
    "notebook_init()\n",
    "\n",
    "\n",
    "from notebooks.deps.binary_predictive_performance import run_roc_analysis, get_pr_analysis\n",
    "from notebooks.deps.binary_predictive_performance import get_pr_analysis, get_pr_analysis_ci, plot_pr_ci\n",
    "\n",
    "from mlflow import set_tracking_uri\n",
    "from notebooks.deps.config import TIME_POINT_PREDICTION\n",
    "from deps.common import get_data_cached\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from pandas import DataFrame\n",
    "from plotly.graph_objs import Figure\n",
    "\n",
    "from deps.constants import RANDOM_STATE\n",
    "from hcve_lib.evaluation_functions import average_group_scores, merge_standardize_prediction, merge_predictions, \\\n",
    "    compute_metrics_prediction\n",
    "from hcve_lib.metrics import BootstrappedMetric\n",
    "from hcve_lib.tracking import load_group_results\n",
    "from hcve_lib.visualisation import setup_plotly_style\n",
    "from hcve_lib.functional import t\n",
    "import numpy as np\n",
    "from hcve_lib.metrics import statistic_from_bootstrap\n",
    "from hcve_lib.functional import reject_none\n",
    "from plotly import express as px\n",
    "from hcve_lib.utils import transpose_list\n",
    "from notebooks.deps.binary_predictive_performance import run_pr_analysis_ci\n",
    "\n",
    "from config import GROUPS_LCO, GROUPS_10_fold\n",
    "from hcve_lib.metrics import BinaryMetricFromScore\n",
    "from hcve_lib.data import binarize_event\n",
    "\n",
    "set_tracking_uri('http://localhost:5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading get_data...\n",
      "____________________________________________get_data cache loaded - 0.0s, 0.0min\n"
     ]
    }
   ],
   "source": [
    "data, metadata, X, y = get_data_cached()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hcve_lib.functional import dict_subset\n",
    "\n",
    "GROUPS = dict_subset(['gb', 'coxnet', 'stacking', 'pcp_hf'], GROUPS_LCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TIME_POINT_PREDICTION = 10*365\n",
    "ITERATIONS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Counting cases/controls with binarization at end-point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "{0.0: 29286, 1.0: 1068}\n",
      "↓\n",
      "Binarization 10.0 years (NA removed)\n",
      "{0.0: -27294, 1.0: -177}\n",
      "↓\n",
      "{0.0: 1992, 1.0: 891}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sitnarf/projects/hcve_lib/hcve_lib/data.py:247: FutureWarning:\n",
      "\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binarized = binarize_event(TIME_POINT_PREDICTION, y['data'], drop_censored=False)\n",
    "\n",
    "print('Before')\n",
    "print(y['data']['label'].value_counts().to_dict())\n",
    "print('↓')\n",
    "print(f'Binarization {TIME_POINT_PREDICTION/365} years (NA removed)')\n",
    "print((binarized.value_counts() - y['data']['label'].value_counts()).to_dict())\n",
    "print('↓')\n",
    "print(binarized.value_counts(dropna=True).to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from toolz import valmap \n",
    "\n",
    "merged_prediction = valmap(\n",
    "    lambda group_id: merge_predictions(average_group_scores(load_group_results(group_id))),\n",
    "    GROUPS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sitnarf/projects/hcve_lib/hcve_lib/data.py:247: FutureWarning:\n",
      "\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_binarized = binarize_event(10*365, y['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HEALTHABC': 2188, 'ASCOT': 243, 'FLEMENGHO': 219, 'PROSPER': 191, 'PREDICTOR': 31, 'HVC': 11}\n"
     ]
    }
   ],
   "source": [
    "print(data.loc[y_binarized.index]['STUDY'].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['gb', 'coxnet', 'stacking', 'pcp_hf'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_prediction.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Per cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from hcve_lib.visualisation import b\n",
    "from hcve_lib.data import binarize_event\n",
    "from hcve_lib.utils import is_noneish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>ASCOT</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "{0.0: 19010, 1.0: 243}\n",
      "↓\n",
      "Binarization 10.0 years (NA removed)\n",
      "{0.0: -19010, 1.0: 0.0}\n",
      "↓\n",
      "{1.0: 243}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sitnarf/projects/hcve_lib/hcve_lib/data.py:247: FutureWarning:\n",
      "\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>FLEMENGHO</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "{0.0: 1083, 1.0: 18}\n",
      "↓\n",
      "Binarization 10.0 years (NA removed)\n",
      "{0.0: -882, 1.0: 0}\n",
      "↓\n",
      "{0.0: 201, 1.0: 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sitnarf/projects/hcve_lib/hcve_lib/data.py:247: FutureWarning:\n",
      "\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>HEALTHABC</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "{0.0: 2361, 1.0: 574}\n",
      "↓\n",
      "Binarization 10.0 years (NA removed)\n",
      "{0.0: -570, 1.0: -177}\n",
      "↓\n",
      "{0.0: 1791, 1.0: 397}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sitnarf/projects/hcve_lib/hcve_lib/data.py:247: FutureWarning:\n",
      "\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>HVC</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "{0.0: 425, 1.0: 11}\n",
      "↓\n",
      "Binarization 10.0 years (NA removed)\n",
      "{0.0: -425, 1.0: 0.0}\n",
      "↓\n",
      "{1.0: 11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sitnarf/projects/hcve_lib/hcve_lib/data.py:247: FutureWarning:\n",
      "\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PREDICTOR</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "{0.0: 1432, 1.0: 31}\n",
      "↓\n",
      "Binarization 10.0 years (NA removed)\n",
      "{0.0: -1432, 1.0: 0.0}\n",
      "↓\n",
      "{1.0: 31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sitnarf/projects/hcve_lib/hcve_lib/data.py:247: FutureWarning:\n",
      "\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PROSPER</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "{0.0: 4975, 1.0: 191}\n",
      "↓\n",
      "Binarization 10.0 years (NA removed)\n",
      "{0.0: -4975, 1.0: 0.0}\n",
      "↓\n",
      "{1.0: 191}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sitnarf/projects/hcve_lib/hcve_lib/data.py:247: FutureWarning:\n",
      "\n",
      "The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deps.data import group_by_study\n",
    "\n",
    "for study, study_X in group_by_study(data, X):\n",
    "    b(study)\n",
    "    binarized = binarize_event(TIME_POINT_PREDICTION, y['data'].loc[study_X.index], drop_censored=False)\n",
    "    print('Before')\n",
    "    before = y['data'].loc[study_X.index]['label'].value_counts()\n",
    "    print(before.to_dict())\n",
    "    print('↓')\n",
    "    print(f'Binarization {TIME_POINT_PREDICTION/365} years (NA removed)')\n",
    "    after = (binarized.value_counts() - before).to_dict()\n",
    "    for value, count in after.items():\n",
    "        if is_noneish(count):\n",
    "            after[value] = - before[value]\n",
    "    print(after)\n",
    "    print('↓')\n",
    "    print(binarized.value_counts(dropna=True).to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## PR analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_age_metric(metric):\n",
    "     return StratifiedMetric(\n",
    "        metric,\n",
    "        splits={'30_to_80': list(get_30_to_80(X).index)}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from hcve_lib.metrics import StratifiedMetric\n",
    "from deps.data import get_30_to_80\n",
    "\n",
    "pr_metrics_unweighted = (\n",
    "    BinaryMetricFromScore(precision_recall_curve_with_confusion, time=TIME_POINT_PREDICTION, sample_weight=None),\n",
    ")\n",
    "\n",
    "pr_metrics_unweighted_summary = (\n",
    "    BinaryMetricFromScore(average_precision_score, time=TIME_POINT_PREDICTION, sample_weight=None),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inverse_weight_cohorts = map_inverse_weight(data['STUDY'].loc[y_binarized.index])\n",
    "\n",
    "pr_metrics_weighted_cohorts = [\n",
    "    ((BinaryMetricFromScore(precision_recall_curve_with_confusion, time=TIME_POINT_PREDICTION, sample_weight=inverse_weight_cohorts))),\n",
    "    ((BinaryMetricFromScore(average_precision_score, time=TIME_POINT_PREDICTION, sample_weight=inverse_weight_cohorts))),\n",
    "]\n",
    "\n",
    "\n",
    "pr_metrics_weighted_cohorts = (\n",
    "    BinaryMetricFromScore(precision_recall_curve_with_confusion, time=TIME_POINT_PREDICTION, sample_weight=inverse_weight_cohorts),\n",
    ")\n",
    "\n",
    "pr_metrics_weighted_cohorts_summary = (\n",
    "    BinaryMetricFromScore(average_precision_score, time=TIME_POINT_PREDICTION, sample_weight=inverse_weight_cohorts),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inverse_incident_weight = map_inverse_weight(y_binarized, proportions={1:0.03, 0: 0.97})\n",
    "\n",
    "pr_metrics_incidence_weighted = [\n",
    "    (BinaryMetricFromScore(precision_recall_curve_with_confusion, time=TIME_POINT_PREDICTION, sample_weight=inverse_incident_weight)),\n",
    "    (BinaryMetricFromScore(average_precision_score, time=TIME_POINT_PREDICTION, sample_weight=inverse_incident_weight)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "combined_weight = (inverse_weight_cohorts*inverse_incident_weight).dropna()\n",
    "\n",
    "pr_metrics_incidence_cohort_weighted = [\n",
    "    BinaryMetricFromScore(precision_recall_curve_with_confusion, time=TIME_POINT_PREDICTION, sample_weight=combined_weight),\n",
    "    BinaryMetricFromScore(average_precision_score, time=TIME_POINT_PREDICTION, sample_weight=combined_weight),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pr_analysis(GROUPS, y, metrics=pr_metrics_unweighted, metrics_summary=pr_metrics_unweighted_summary, standardize=False, iterations=ITERATIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]14.8s, 0.2min   : Loading load_group_results...\n",
      "_________________________________load_group_results cache loaded - 43.6s, 0.7min\n",
      "[Memory]305.6s, 5.1min  : Loading load_group_results...\n",
      "_________________________________load_group_results cache loaded - 12.4s, 0.2min\n",
      "[Memory]564.8s, 9.4min  : Loading load_group_results...\n",
      "_________________________________load_group_results cache loaded - 45.0s, 0.7min\n",
      "[Memory]819.4s, 13.7min : Loading load_group_results...\n",
      "__________________________________load_group_results cache loaded - 0.1s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sitnarf/projects/hcve_lib/hcve_lib/metrics.py:187: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in double_scalars\n",
      "\n",
      "/home/sitnarf/projects/hcve_lib/hcve_lib/metrics.py:187: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr = get_pr_analysis(GROUPS, y, metrics=pr_metrics_unweighted, standardize=False, iterations=ITERATIONS)\n",
    "pr_ci = get_pr_analysis_ci(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]1071.0s, 17.8min: Loading load_group_results...\n",
      "_________________________________load_group_results cache loaded - 41.4s, 0.7min\n",
      "[Memory]1118.2s, 18.6min: Loading load_group_results...\n",
      "_________________________________load_group_results cache loaded - 11.3s, 0.2min\n",
      "[Memory]1134.5s, 18.9min: Loading load_group_results...\n",
      "_________________________________load_group_results cache loaded - 43.1s, 0.7min\n",
      "[Memory]1183.3s, 19.7min: Loading load_group_results...\n",
      "__________________________________load_group_results cache loaded - 0.1s, 0.0min\n"
     ]
    }
   ],
   "source": [
    "pr_summary = get_pr_analysis(\n",
    "    GROUPS,\n",
    "    y=y,\n",
    "    metrics=[\n",
    "        BinaryMetricFromScore(\n",
    "            average_precision_score,\n",
    "            time=TIME_POINT_PREDICTION,\n",
    "            sample_weight=None,\n",
    "        ),\n",
    "    ],\n",
    "    standardize=False,\n",
    "    iterations=ITERATIONS,\n",
    "    return_summary=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gb': {'average_precision_score_3650': {'mean': 0.5411641398489965,\n",
       "   'ci': (0.511775463744616, 0.5659141739484992),\n",
       "   'std': 0.01522466281743794}},\n",
       " 'coxnet': {'average_precision_score_3650': {'mean': 0.4767401664086349,\n",
       "   'ci': (0.44795480419045514, 0.5083342226095958),\n",
       "   'std': 0.016382174761818795}},\n",
       " 'stacking': {'average_precision_score_3650': {'mean': 0.8043644645039191,\n",
       "   'ci': (0.782005272182563, 0.825385330538736),\n",
       "   'std': 0.010842991136348375}},\n",
       " 'pcp_hf': {'average_precision_score_3650': {'mean': 0.5503647911860816,\n",
       "   'ci': (0.5247046288934044, 0.5824265386248236),\n",
       "   'std': 0.014850461379101242}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_pr_ci(pr_ci, pr_summary)\n",
    "fig.write_image('./output/pr_final.svg')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: enable or disable\n",
    "# from hcve_lib.wrapped_sklearn import DFStandardScaler\n",
    "# import dtale\n",
    "\n",
    "# predictions = DFStandardScaler().fit_transform(DataFrame({\n",
    "#     'gb': merged_prediction['gb']['y_score'],\n",
    "#     'coxnet': merged_prediction['coxnet']['y_score'],\n",
    "#     'pcp_hf': merged_prediction['pcp_hf']['y_score'],\n",
    "#     'stacking': merged_prediction['stacking']['y_score'],\n",
    "# }\n",
    "# ))\n",
    "# predictions['y'] = y_binarized\n",
    "# predictions.dropna(inplace=True)\n",
    "# predictions['STUDY'] = data['STUDY'].loc[predictions.index]\n",
    "\n",
    "# dtale.show(predictions.sample(len(predictions), weights=inverse_incident_weight, replace=True), host='localhost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incidence normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]13049.7s, 217.5min: Loading load_group_results...\n",
      "_________________________________load_group_results cache loaded - 84.4s, 1.4min\n",
      "[Memory]13686.1s, 228.1min: Loading load_group_results...\n",
      "_________________________________load_group_results cache loaded - 22.1s, 0.4min\n",
      "[Memory]14266.4s, 237.8min: Loading load_group_results...\n",
      "_________________________________load_group_results cache loaded - 80.1s, 1.3min\n",
      "[Memory]14814.2s, 246.9min: Loading load_group_results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sitnarf/projects/hcve_lib/hcve_lib/metrics.py:187: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in double_scalars\n",
      "\n",
      "/home/sitnarf/projects/hcve_lib/hcve_lib/metrics.py:187: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________load_group_results cache loaded - 0.2s, 0.0min\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_pr_analysis() got an unexpected keyword argument 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_pr_analysis_ci\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mGROUPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpr_metrics_weighted_cohorts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics_summary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpr_metrics_weighted_cohorts_summary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstandardize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mITERATIONS\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/projects/homage-fl/notebooks/deps/binary_predictive_performance.py:109\u001b[0m, in \u001b[0;36mrun_pr_analysis_ci\u001b[0;34m(groups, y, metrics, metrics_summary, standardize, iterations)\u001b[0m\n\u001b[1;32m    107\u001b[0m pr \u001b[38;5;241m=\u001b[39m get_pr_analysis(groups, y\u001b[38;5;241m=\u001b[39my, metrics\u001b[38;5;241m=\u001b[39mmetrics, standardize\u001b[38;5;241m=\u001b[39mstandardize, iterations\u001b[38;5;241m=\u001b[39miterations)\n\u001b[1;32m    108\u001b[0m pr_ci \u001b[38;5;241m=\u001b[39m get_pr_analysis_ci(pr)\n\u001b[0;32m--> 109\u001b[0m pr_summary \u001b[38;5;241m=\u001b[39m \u001b[43mget_pr_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics_summary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstandardize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstandardize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot_pr_ci(pr_ci, pr_summary)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_pr_analysis() got an unexpected keyword argument 'summary'"
     ]
    }
   ],
   "source": [
    "run_pr_analysis_ci(\n",
    "    GROUPS,\n",
    "    y,\n",
    "    metrics=pr_metrics_weighted_cohorts,\n",
    "    metrics_summary=pr_metrics_weighted_cohorts_summary,\n",
    "    standardize=False,\n",
    "    iterations=ITERATIONS\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohort normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]12883.9s, 214.7min: Loading load_group_results...\n",
      "_________________________________load_group_results cache loaded - 41.7s, 0.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_pr_analysis_ci(\n",
    "    GROUPS,\n",
    "    y,\n",
    "    metrics=pr_metrics_incidence_weighted,\n",
    "    metrics_summary=pr_metrics_incidence_weighted,\n",
    "    standardize=False,\n",
    "    iterations=ITERATIONS\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pr_summary = get_pr_analysis(\n",
    "    GROUPS,\n",
    "    y=y,\n",
    "    metrics=[\n",
    "        BinaryMetricFromScore(\n",
    "            average_precision_score,\n",
    "            time=TIME_POINT_PREDICTION,\n",
    "            sample_weight=inverse_weight_cohorts\n",
    "        ),\n",
    "    ],\n",
    "    standardize=False,\n",
    "    iterations=ITERATIONS,\n",
    "    return_summary=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pr_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = get_pr_analysis(\n",
    "    GROUPS,\n",
    "    y=y,\n",
    "    metrics=[\n",
    "        BinaryMetricFromScore(\n",
    "            average_precision_score,\n",
    "            time=TIME_POINT_PREDICTION,\n",
    "            sample_weight=inverse_weight_cohorts\n",
    "        ),\n",
    "    ],\n",
    "    standardize=False,\n",
    "    iterations=5,\n",
    "    return_summary=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import ttest_ind\n",
    "from pandas import Series\n",
    "from numpy.random import seed\n",
    "from numpy.random import randint\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "scores_df = {method: merged_metrics_selected[method]['c_index'] for method in ['coxnet', 'gb', 'pcp_hf', 'stacking']}\n",
    "\n",
    "for (name1, s1), (name2, s2) in combinations(scores_df.items(), 2):\n",
    "    print(name1, name2)\n",
    "    print(', '.join([f'{v:.2f}' for v in Series(s1).sample(10)]))\n",
    "    print(', '.join([f'{v:.2f}' for v in Series(s2).sample(10)]))\n",
    "    \n",
    "    ks = ks_2samp(s1, s2)\n",
    "    print(f\"KS: {ks.statistic:.4f} (p-value: {ks.pvalue:.1e})\")\n",
    "    \n",
    "    value, pvalue = ttest_ind(s1, s2)\n",
    "    print(f\"t-test: p-value: {pvalue:.1e}\")\n",
    "    \n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ROC analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "roc_metrics_unweighted = [\n",
    "    BinaryMetricFromScore(roc_curve, time=TIME_POINT_PREDICTION, sample_weight=None),\n",
    "    BinaryMetricFromScore(roc_auc_score, time=TIME_POINT_PREDICTION, sample_weight=None),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_roc_analysis(GROUPS, roc_metrics_unweighted, standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_roc_analysis(GROUPS, roc_metrics_unweighted, standardize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inverse_weight = get_inverse_weight(data['STUDY'])\n",
    "\n",
    "roc_metrics_weighted = [\n",
    "    BinaryMetricFromScore(roc_curve, time=TIME_POINT_PREDICTION, sample_weight=inverse_weight),\n",
    "    BinaryMetricFromScore(roc_auc_score, time=TIME_POINT_PREDICTION, sample_weight=inverse_weight),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_roc_analysis(GROUPS, roc_metrics_weighted, standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_roc_analysis(GROUPS, roc_metrics_weighted, standardize=False)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "679.05px",
    "left": "89px",
    "top": "110.833px",
    "width": "345.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
